{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W3tIG4lucieJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679b809a-94d8-426f-e980-38643c3825b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting navec\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec) (1.21.6)\n",
            "Installing collected packages: navec\n",
            "Successfully installed navec-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Collecting tensorflow<2.11,>=2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (4.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.19.6)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.3.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.2.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 76.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.27.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (14.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.50.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.10.26 keras-2.10.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-text-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install navec\n",
        "!pip install tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "from navec import Navec"
      ],
      "metadata": {
        "id": "nK_Afj6Jg6BC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Nl2SqlTranslator(tf.keras.Model):\n",
        "    def __init__(self, nl_text_processor, sql_text_processor, navec, unit=300):\n",
        "        super().__init__()\n",
        "        # Natural language\n",
        "        self.nl_text_processor = nl_text_processor\n",
        "        self.nl_voba_size = len(nl_text_processor.get_vocabulary())\n",
        "        \n",
        "        self.nl_embedding = tf.keras.layers.Embedding(\n",
        "            self.nl_voba_size,\n",
        "            output_dim=unit,\n",
        "            mask_zero=True)\n",
        "        \n",
        "        fixed_embedding_matrix = np.zeros((self.nl_voba_size, unit))\n",
        "        for i, word in enumerate(nl_text_processor.get_vocabulary()):\n",
        "            fixed_embedding_matrix[i] = navec.get(word, navec['<pad>'])\n",
        "        self.fixed_embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=self.nl_voba_size,\n",
        "            output_dim=unit,\n",
        "            embeddings_initializer=tf.keras.initializers.Constant(fixed_embedding_matrix),\n",
        "            trainable=False,\n",
        "            mask_zero=True)\n",
        "        \n",
        "        self.nl_rnn = tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(int(unit/2), return_sequences=True, return_state=True))\n",
        "        # Attention\n",
        "        self.attention = tf.keras.layers.Attention()\n",
        "        # SQL\n",
        "        self.sql_text_processor = sql_text_processor\n",
        "        self.sql_voba_size = len(sql_text_processor.get_vocabulary())\n",
        "        self.sql_embedding = tf.keras.layers.Embedding(\n",
        "            self.sql_voba_size,\n",
        "            output_dim=unit,\n",
        "            mask_zero=True)\n",
        "        self.sql_rnn = tf.keras.layers.LSTM(unit, return_sequences=True, return_state=True)\n",
        "        # Output\n",
        "        self.out = tf.keras.layers.Dense(self.sql_voba_size)\n",
        "            \n",
        "    def __call__(self, nl_text, sql_text, training=True):\n",
        "        nl_tokens = self.nl_text_processor(nl_text) # Shape: (batch, Ts)\n",
        "        nl_vectors = self.nl_embedding(nl_tokens, training=training) # Shape: (batch, Ts, embedding_dim)\n",
        "        nl_fixed_vectors = self.fixed_embedding(nl_tokens) # Shape: (batch, Ts, 100)\n",
        "        nl_combined_vectors = tf.concat([nl_vectors, nl_fixed_vectors], -1) # Shape: (batch, Ts, embedding_dim+100)\n",
        "        nl_rnn_out, fhstate, fcstate, bhstate, bcstate = self.nl_rnn(nl_combined_vectors, training=training) # Shape: (batch, Ts, bi_rnn_output_dim), (batch, rnn_output_dim) ...\n",
        "        nl_hstate = tf.concat([fhstate, bhstate], -1)\n",
        "        nl_cstate = tf.concat([fcstate, bcstate], -1)\n",
        "        \n",
        "        sql_tokens = self.sql_text_processor(sql_text) # Shape: (batch, Te)\n",
        "        expected = sql_tokens[:,1:] # Shape: (batch, Te-1)\n",
        "        \n",
        "        teacher_forcing = sql_tokens[:,:-1] # Shape: (batch, Te-1)\n",
        "        sql_vectors = self.sql_embedding(teacher_forcing, training=training) # Shape: (batch, Te-1, embedding_dim)\n",
        "        sql_in = self.attention(inputs=[sql_vectors,nl_rnn_out], mask=[sql_vectors._keras_mask, nl_rnn_out._keras_mask], training=training)\n",
        "        \n",
        "        trans_vectors, _, _ = self.sql_rnn(sql_in, initial_state=[nl_hstate, nl_cstate], training=training) # Shape: (batch, Te-1, rnn_output_dim)\n",
        "        out = self.out(trans_vectors, training=training) # Shape: (batch, Te-1, sql_vocab_size)\n",
        "        return out, expected, out._keras_mask"
      ],
      "metadata": {
        "id": "GRWN3pQPg3j8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs, model, batch=64, shuffle=1000):\n",
        "    loss_fcn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True,\n",
        "        reduction=tf.keras.losses.Reduction.NONE)\n",
        "    opt = tf.keras.optimizers.Adam()\n",
        "    losses = []\n",
        "    ds = dataset.shuffle(shuffle).batch(batch).cache()\n",
        "    \n",
        "    print(\"Training started...\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        epoch_losses = []\n",
        "        for nl_text, sql_text in ds:\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits, expected, mask = model(nl_text, sql_text)\n",
        "                loss = loss_fcn(expected, logits)\n",
        "                loss = tf.ragged.boolean_mask(loss, mask)\n",
        "                loss = tf.reduce_sum(loss) * (1. / batch)\n",
        "                epoch_losses.append(loss.numpy())\n",
        "                grads = tape.gradient(loss, model.trainable_weights)\n",
        "                opt.apply_gradients(zip(grads, model.trainable_weights))\n",
        "        losses.append(np.mean(epoch_losses))\n",
        "        print('Trained epoch: {}; loss: {}'.format(epoch, losses[epoch]))\n",
        "        \n",
        "    plt.plot(losses)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Losses')"
      ],
      "metadata": {
        "id": "X0o_98wchZjB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(text):\n",
        "    parts = tf.strings.split(text, sep='\\t')\n",
        "    return parts[0], parts[1]"
      ],
      "metadata": {
        "id": "P72g3mJoheSO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(text):\n",
        "    # Split accecented characters.\n",
        "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "    text = tf.strings.lower(text)\n",
        "    # # Keep space, a to z, and select punctuation.\n",
        "    # text = tf.strings.regex_replace(text, '[^\\w\\s.?!,:;\\{\\}\\(\\)\\[\\]]', '')\n",
        "    # # Add spaces around punctuation.\n",
        "    # text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "    # Strip whitespace.\n",
        "    text = tf.strings.strip(text)\n",
        "\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text"
      ],
      "metadata": {
        "id": "19pS9jQtiGQd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.TextLineDataset(['nl2sql.txt']).map(split)\n",
        "nl_dataset = dataset.map(lambda nl, sql: nl)\n",
        "sql_dataset = dataset.map(lambda nl, sql: sql)"
      ],
      "metadata": {
        "id": "ug01a6xrhhlT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nl_text_processor = tf.keras.layers.TextVectorization(standardize=standardize, max_tokens=5000)\n",
        "sql_text_processor = tf.keras.layers.TextVectorization(standardize=standardize, max_tokens=5000)\n",
        "nl_text_processor.adapt(nl_dataset.batch(64))\n",
        "sql_text_processor.adapt(sql_dataset.batch(64))"
      ],
      "metadata": {
        "id": "D03P7uLCiK4C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
        "navec = Navec.load(path)"
      ],
      "metadata": {
        "id": "xUjFMZ7MiOPI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Nl2SqlTranslator(nl_text_processor, sql_text_processor, navec)"
      ],
      "metadata": {
        "id": "XvDNn0AdiyI3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(dataset, 150, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HLb2p0Hli8JL",
        "outputId": "86316d50-0887-413a-fbb6-b6a84759316e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started...\n",
            "Trained epoch: 0; loss: 64.22322082519531\n",
            "Trained epoch: 1; loss: 63.31948471069336\n",
            "Trained epoch: 2; loss: 62.11433792114258\n",
            "Trained epoch: 3; loss: 59.98335266113281\n",
            "Trained epoch: 4; loss: 56.31269836425781\n",
            "Trained epoch: 5; loss: 52.59640884399414\n",
            "Trained epoch: 6; loss: 50.52315139770508\n",
            "Trained epoch: 7; loss: 48.9955940246582\n",
            "Trained epoch: 8; loss: 47.619773864746094\n",
            "Trained epoch: 9; loss: 46.37248229980469\n",
            "Trained epoch: 10; loss: 45.50846481323242\n",
            "Trained epoch: 11; loss: 44.73655319213867\n",
            "Trained epoch: 12; loss: 43.90521240234375\n",
            "Trained epoch: 13; loss: 43.0961799621582\n",
            "Trained epoch: 14; loss: 42.4491081237793\n",
            "Trained epoch: 15; loss: 41.86153030395508\n",
            "Trained epoch: 16; loss: 41.230228424072266\n",
            "Trained epoch: 17; loss: 40.52061462402344\n",
            "Trained epoch: 18; loss: 39.77604675292969\n",
            "Trained epoch: 19; loss: 39.04479217529297\n",
            "Trained epoch: 20; loss: 38.279396057128906\n",
            "Trained epoch: 21; loss: 37.443641662597656\n",
            "Trained epoch: 22; loss: 36.576969146728516\n",
            "Trained epoch: 23; loss: 35.68498611450195\n",
            "Trained epoch: 24; loss: 34.75578308105469\n",
            "Trained epoch: 25; loss: 33.913604736328125\n",
            "Trained epoch: 26; loss: 33.32179641723633\n",
            "Trained epoch: 27; loss: 32.554954528808594\n",
            "Trained epoch: 28; loss: 31.138294219970703\n",
            "Trained epoch: 29; loss: 30.572851181030273\n",
            "Trained epoch: 30; loss: 29.53852081298828\n",
            "Trained epoch: 31; loss: 28.437244415283203\n",
            "Trained epoch: 32; loss: 27.94668197631836\n",
            "Trained epoch: 33; loss: 26.640605926513672\n",
            "Trained epoch: 34; loss: 25.99077606201172\n",
            "Trained epoch: 35; loss: 25.2148494720459\n",
            "Trained epoch: 36; loss: 24.12430763244629\n",
            "Trained epoch: 37; loss: 23.61384391784668\n",
            "Trained epoch: 38; loss: 22.706218719482422\n",
            "Trained epoch: 39; loss: 21.771764755249023\n",
            "Trained epoch: 40; loss: 21.280588150024414\n",
            "Trained epoch: 41; loss: 20.628053665161133\n",
            "Trained epoch: 42; loss: 19.69961929321289\n",
            "Trained epoch: 43; loss: 19.09391975402832\n",
            "Trained epoch: 44; loss: 18.725147247314453\n",
            "Trained epoch: 45; loss: 18.1358642578125\n",
            "Trained epoch: 46; loss: 17.267518997192383\n",
            "Trained epoch: 47; loss: 16.65598487854004\n",
            "Trained epoch: 48; loss: 16.353607177734375\n",
            "Trained epoch: 49; loss: 15.73206615447998\n",
            "Trained epoch: 50; loss: 15.07716178894043\n",
            "Trained epoch: 51; loss: 14.622966766357422\n",
            "Trained epoch: 52; loss: 14.290925979614258\n",
            "Trained epoch: 53; loss: 13.857645988464355\n",
            "Trained epoch: 54; loss: 13.266677856445312\n",
            "Trained epoch: 55; loss: 12.712702751159668\n",
            "Trained epoch: 56; loss: 12.345498085021973\n",
            "Trained epoch: 57; loss: 12.106201171875\n",
            "Trained epoch: 58; loss: 11.790007591247559\n",
            "Trained epoch: 59; loss: 11.291484832763672\n",
            "Trained epoch: 60; loss: 10.73387622833252\n",
            "Trained epoch: 61; loss: 10.39998722076416\n",
            "Trained epoch: 62; loss: 10.20150375366211\n",
            "Trained epoch: 63; loss: 9.920482635498047\n",
            "Trained epoch: 64; loss: 9.4789457321167\n",
            "Trained epoch: 65; loss: 9.025771141052246\n",
            "Trained epoch: 66; loss: 8.828242301940918\n",
            "Trained epoch: 67; loss: 8.644122123718262\n",
            "Trained epoch: 68; loss: 8.292669296264648\n",
            "Trained epoch: 69; loss: 7.884164810180664\n",
            "Trained epoch: 70; loss: 7.663422107696533\n",
            "Trained epoch: 71; loss: 7.506431579589844\n",
            "Trained epoch: 72; loss: 7.261266231536865\n",
            "Trained epoch: 73; loss: 6.929649829864502\n",
            "Trained epoch: 74; loss: 6.683688640594482\n",
            "Trained epoch: 75; loss: 6.56373929977417\n",
            "Trained epoch: 76; loss: 6.315633296966553\n",
            "Trained epoch: 77; loss: 6.0654449462890625\n",
            "Trained epoch: 78; loss: 5.864988803863525\n",
            "Trained epoch: 79; loss: 5.729862213134766\n",
            "Trained epoch: 80; loss: 5.5436553955078125\n",
            "Trained epoch: 81; loss: 5.3229193687438965\n",
            "Trained epoch: 82; loss: 5.150347709655762\n",
            "Trained epoch: 83; loss: 5.015382766723633\n",
            "Trained epoch: 84; loss: 4.859062194824219\n",
            "Trained epoch: 85; loss: 4.677611351013184\n",
            "Trained epoch: 86; loss: 4.521964073181152\n",
            "Trained epoch: 87; loss: 4.390748023986816\n",
            "Trained epoch: 88; loss: 4.268456935882568\n",
            "Trained epoch: 89; loss: 4.123606204986572\n",
            "Trained epoch: 90; loss: 3.9830169677734375\n",
            "Trained epoch: 91; loss: 3.85445499420166\n",
            "Trained epoch: 92; loss: 3.7454330921173096\n",
            "Trained epoch: 93; loss: 3.6384990215301514\n",
            "Trained epoch: 94; loss: 3.5241620540618896\n",
            "Trained epoch: 95; loss: 3.4071576595306396\n",
            "Trained epoch: 96; loss: 3.294023036956787\n",
            "Trained epoch: 97; loss: 3.1947813034057617\n",
            "Trained epoch: 98; loss: 3.103147029876709\n",
            "Trained epoch: 99; loss: 3.0148839950561523\n",
            "Trained epoch: 100; loss: 2.9244582653045654\n",
            "Trained epoch: 101; loss: 2.831599473953247\n",
            "Trained epoch: 102; loss: 2.7404658794403076\n",
            "Trained epoch: 103; loss: 2.6543571949005127\n",
            "Trained epoch: 104; loss: 2.5745999813079834\n",
            "Trained epoch: 105; loss: 2.5007264614105225\n",
            "Trained epoch: 106; loss: 2.430027723312378\n",
            "Trained epoch: 107; loss: 2.36065411567688\n",
            "Trained epoch: 108; loss: 2.2910516262054443\n",
            "Trained epoch: 109; loss: 2.222426652908325\n",
            "Trained epoch: 110; loss: 2.156297206878662\n",
            "Trained epoch: 111; loss: 2.0939881801605225\n",
            "Trained epoch: 112; loss: 2.0360097885131836\n",
            "Trained epoch: 113; loss: 1.9807734489440918\n",
            "Trained epoch: 114; loss: 1.9268453121185303\n",
            "Trained epoch: 115; loss: 1.8732290267944336\n",
            "Trained epoch: 116; loss: 1.8207308053970337\n",
            "Trained epoch: 117; loss: 1.7705997228622437\n",
            "Trained epoch: 118; loss: 1.723138689994812\n",
            "Trained epoch: 119; loss: 1.678090214729309\n",
            "Trained epoch: 120; loss: 1.6342220306396484\n",
            "Trained epoch: 121; loss: 1.5910848379135132\n",
            "Trained epoch: 122; loss: 1.5491886138916016\n",
            "Trained epoch: 123; loss: 1.5091880559921265\n",
            "Trained epoch: 124; loss: 1.4717854261398315\n",
            "Trained epoch: 125; loss: 1.4360578060150146\n",
            "Trained epoch: 126; loss: 1.4013811349868774\n",
            "Trained epoch: 127; loss: 1.3669993877410889\n",
            "Trained epoch: 128; loss: 1.3338916301727295\n",
            "Trained epoch: 129; loss: 1.3022860288619995\n",
            "Trained epoch: 130; loss: 1.2720571756362915\n",
            "Trained epoch: 131; loss: 1.2426878213882446\n",
            "Trained epoch: 132; loss: 1.2141225337982178\n",
            "Trained epoch: 133; loss: 1.1866412162780762\n",
            "Trained epoch: 134; loss: 1.1602723598480225\n",
            "Trained epoch: 135; loss: 1.1346826553344727\n",
            "Trained epoch: 136; loss: 1.1097110509872437\n",
            "Trained epoch: 137; loss: 1.0854054689407349\n",
            "Trained epoch: 138; loss: 1.0620481967926025\n",
            "Trained epoch: 139; loss: 1.0394359827041626\n",
            "Trained epoch: 140; loss: 1.017427682876587\n",
            "Trained epoch: 141; loss: 0.9959810972213745\n",
            "Trained epoch: 142; loss: 0.975234866142273\n",
            "Trained epoch: 143; loss: 0.9551839232444763\n",
            "Trained epoch: 144; loss: 0.9356545805931091\n",
            "Trained epoch: 145; loss: 0.916607677936554\n",
            "Trained epoch: 146; loss: 0.898110568523407\n",
            "Trained epoch: 147; loss: 0.8801743388175964\n",
            "Trained epoch: 148; loss: 0.8627141714096069\n",
            "Trained epoch: 149; loss: 0.8456567525863647\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(nl_text, model, max_seq=100):\n",
        "    nl_tokens = model.nl_text_processor([tf.constant(nl_text)]) # Shape: (batch, Ts)\n",
        "    nl_vectors = model.nl_embedding(nl_tokens, training=False) # Shape: (batch, Ts, embedding_dim)\n",
        "    nl_fixed_vectors = model.fixed_embedding(nl_tokens) # Shape: (batch, Ts, 100)\n",
        "    nl_combined_vectors = tf.concat([nl_vectors, nl_fixed_vectors], -1) # Shape: (batch, Ts, embedding_dim+100)\n",
        "    nl_rnn_out, fhstate, fcstate, bhstate, bcstate = model.nl_rnn(nl_combined_vectors, training=False) # Shape: (batch, Ts, bi_rnn_output_dim), (batch, rnn_output_dim) ...\n",
        "    nl_hstate = tf.concat([fhstate, bhstate], -1)\n",
        "    nl_cstate = tf.concat([fcstate, bcstate], -1)\n",
        "    state = [nl_hstate, nl_cstate]\n",
        "\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=model.sql_text_processor.get_vocabulary(),\n",
        "        mask_token='')\n",
        "    trans = ['[START]']\n",
        "    vectors = []\n",
        "\n",
        "    for i in range(max_seq):\n",
        "        token = index_from_string([[trans[i]]]) # Shape: (1, 1)\n",
        "        vector = model.sql_embedding(token, training=False) # Shape: (1, 1, embedding_dim)\n",
        "        vectors.append(vector)\n",
        "        query = tf.concat(vectors, axis=1)\n",
        "        context = model.attention(inputs=[query, nl_rnn_out], training=False)\n",
        "        trans_vector, hstate, cstate = model.sql_rnn(context[:,-1:,:], initial_state=state, training=False) # Shape: (1, 1, rnn_output_dim), (1, rnn_output_dim), (1, rnn_output_dim)\n",
        "        state = [hstate, cstate]\n",
        "        out = model.out(trans_vector) # Shape: (1, 1, eng_vocab_size)\n",
        "        out = tf.squeeze(out) # Shape: (eng_vocab_size,)\n",
        "        word_index = tf.math.argmax(out)\n",
        "        word = model.sql_text_processor.get_vocabulary()[word_index]\n",
        "        trans.append(word)\n",
        "        if word == '[END]':\n",
        "            trans = trans[:-1]\n",
        "            break\n",
        "    _, atts = model.attention(inputs=[vectors, nl_rnn_out], return_attention_scores=True, training=False)\n",
        "    return ' '.join(trans[1:]), atts"
      ],
      "metadata": {
        "id": "hzCTbLmYJzwA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"Какие адреса где были соревнования лишь один раз\", model)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yVqBrIbtJ51d",
        "outputId": "273af19b-ab84-4aac-e4ae-2d5093a7e659"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'select * from (select address, count(*) c from sport s group by address) s where c = 1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}